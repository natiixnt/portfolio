<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="AI Python Engineer portfolio for Natalia Szczepanik. LLM, RAG, backend, cloud." />
    <meta name="author" content="Natalia Szczepanik" />
    <title>Natalia Szczepanik - AI Python Engineer | LLM, RAG, Cloud</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favico.ico" />
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@500;600;700&family=DM+Sans:wght@400;500;600&family=JetBrains+Mono:wght@400;600&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-dcKqcVv03Wj7dN0SmHgwlHGawEq+y3OC/YLXTr4Wr9PXgCulvRlQCk2BEmc6kAMPx/+qvOBvyBo3Z7V6m9Rc/w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link href="css/styles.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>
<body>
    <header class="top-nav">
        <div class="logo">NS</div>
        <nav class="nav-links" aria-label="Primary">
            <a href="#about">About</a>
            <a href="#skills">Skills</a>
            <a href="#projects">Projects</a>
            <a href="#timeline">Timeline</a>
            <a href="#contact">Contact</a>
        </nav>
        <div class="nav-actions">
            <a class="btn btn-outline" href="assets/Natalia_Szczepanik_CV.pdf" download>CV</a>
        </div>
    </header>

    <main>
        <section id="hero" class="section hero">
            <div class="hero-grid">
                <div>
                    <p class="eyebrow">AI Python Engineer / Software Engineer (LLM, RAG, Cloud)</p>
                    <h1>I build LLM-powered products, RAG systems and reliable backend services.</h1>
                    <p class="lede">I focus on Python, FastAPI, vector and relational databases, and cloud platforms (Azure/AWS) to turn business problems into production-ready systems. From prototypes to long-term maintenance, I care about data quality, observability and developer experience.</p>
                    <div class="cta-row">
                        <a class="btn btn-primary" href="#projects">View Projects</a>
                        <a class="btn btn-secondary" href="assets/Natalia_Szczepanik_CV.pdf" download>Download CV</a>
                    </div>
                    <div class="hero-tech-pills">
                        <span class="tech-pill">Python</span>
                        <span class="tech-pill">FastAPI</span>
                        <span class="tech-pill">LangChain / LangGraph</span>
                        <span class="tech-pill">RAG</span>
                        <span class="tech-pill">PostgreSQL</span>
                        <span class="tech-pill">Azure &amp; AWS</span>
                    </div>
                </div>
                <div class="hero-card">
                    <div class="hero-badge">Available for remote roles</div>
                    <h3>LLM Infra &amp; Backend</h3>
                    <ul>
                        <li>LLM apps with retrieval, tools and evaluation</li>
                        <li>APIs with strong validation and observability</li>
                        <li>Data pipelines from SQL + file stores to vectors</li>
                        <li>CI/CD and automated regression tests</li>
                    </ul>
                    <div class="metrics hero-stats">
                        <div class="hero-stat">
                            <div class="hero-stat-number">9+ years</div>
                            <div class="hero-stat-label">coding experience</div>
                        </div>
                        <div class="hero-stat">
                            <div class="hero-stat-number">RAG</div>
                            <div class="hero-stat-label">LangChain, Chroma, Pinecone, Weaviate</div>
                        </div>
                        <div class="hero-stat">
                            <div class="hero-stat-number">Cloud</div>
                            <div class="hero-stat-label">Azure Functions, App Service, AWS Lambda/ECS</div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section id="about" class="section about">
            <div class="section-heading">
                <p class="eyebrow">About</p>
                <h2>Engineer with deep Python roots and a focus on LLM systems</h2>
            </div>
            <div class="text-grid">
                <p>I started coding in primary school, building simple games, websites and scripts to automate chores. That curiosity led me to C++ and Python, algorithms and debugging tools. I shipped early side projects for friends and local groups, learning quickly how to make code survive real usage.</p>
                <p>Today I design and ship LLM systems: retrieval-augmented assistants, agentic workflows and evaluation loops that prove reliability. I am comfortable moving between prototypes and long-term maintenance - modeling data, designing APIs, instrumenting logs/metrics and keeping deployments healthy.</p>
                <p>I like collaborating with product and ops teams to make sure AI features solve the right problem. My stack revolves around Python, FastAPI, SQLAlchemy, PostgreSQL/MySQL, vector databases (Pinecone, Weaviate, Chroma), LangChain/LangGraph, Azure/AWS, Docker and CI/CD with testing.</p>
            </div>
        </section>

        <section id="skills" class="section skills">
            <div class="section-heading">
                <p class="eyebrow">Skills</p>
                <h2>Systems thinking with strong Python, backend and cloud foundations</h2>
            </div>
            <div class="card-grid">
                <div class="card">
                    <div class="card-title">GenAI &amp; LLM systems</div>
                    <ul>
                        <li>LLMs: OpenAI, Anthropic, Azure OpenAI</li>
                        <li>Embeddings, tokenization, transformers basics</li>
                        <li>RAG pipelines, vector DBs (Pinecone, Weaviate, Chroma)</li>
                        <li>LangChain, LangGraph, CrewAI style orchestration</li>
                        <li>Prompt engineering, tools/agents, evaluation &amp; monitoring</li>
                    </ul>
                </div>
                <div class="card">
                    <div class="card-title">Python &amp; backend engineering</div>
                    <ul>
                        <li>Python, FastAPI, REST API design, background workers</li>
                        <li>ORMs: SQLAlchemy; PostgreSQL/MySQL schemas &amp; migrations</li>
                        <li>Unit/integration tests with pytest, clean architecture</li>
                        <li>Validation, business rules, error handling &amp; logging</li>
                    </ul>
                </div>
                <div class="card">
                    <div class="card-title">Cloud &amp; DevOps</div>
                    <ul>
                        <li>Azure: Functions, App Service, Storage, Key Vault</li>
                        <li>AWS: Lambda, S3, ECS, IAM, Bedrock</li>
                        <li>Docker, basic Kubernetes, CI/CD (GitHub Actions, GitLab CI)</li>
                        <li>Logging, metrics, monitoring, pragmatic MLOps patterns</li>
                    </ul>
                </div>
                <div class="card">
                    <div class="card-title">Developer experience &amp; automation</div>
                    <ul>
                        <li>Python automation scripts and bots</li>
                        <li>Workflow automation (n8n, Make, Zapier)</li>
                        <li>Internal tools: code review automation, IDE assistants, docs generators</li>
                    </ul>
                </div>
                <div class="card">
                    <div class="card-title">Additional</div>
                    <ul>
                        <li>C++, basic system administration</li>
                        <li>3D modeling (Fusion 360), Adobe Suite, video editing</li>
                    </ul>
                </div>
            </div>
        </section>
        <section id="projects" class="section projects">
            <div class="section-heading">
                <p class="eyebrow">Projects</p>
                <h2>Recent AI + backend builds with real engineering depth</h2>
                <p class="lede">Advanced snippets below are production-oriented: typed Python, FastAPI, SQLAlchemy, tests and automation. Each project includes architecture visuals and deeper notes.</p>
            </div>

            <article class="project-card" id="project-knowledge-assistant">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">LLM Knowledge Assistant for Internal Systems</h3>
                        <p class="sub">Python based assistant that answers questions about internal documentation and database records.</p>
                    </div>
                    <div class="stack">Python  |  FastAPI  |  PostgreSQL  |  SQLAlchemy  |  LangChain  |  OpenAI  |  Azure  |  Docker</div>
                </div>
                <ul class="project-points">
                    <li>Built ETL that pulls relational data and files, normalises them and loads vectors.</li>
                    <li>Designed schemas and views to filter by tenant, source and freshness.</li>
                    <li>Implemented FastAPI endpoints for chat, admin operations and data refresh.</li>
                    <li>Added metrics: latency, sources returned, error counts with structured logging.</li>
                </ul>
                <div class="code-grid">
                    <div class="code-block" data-lang="python" data-title="FastAPI chat endpoint with retrieval &amp; timeouts">
<code>
from __future__ import annotations

import asyncio
import logging
from uuid import UUID, uuid4

from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field, constr

from app.services.chat import ChatService, RetrievalError, get_chat_service

router = APIRouter()
logger = logging.getLogger("app.chat")

class ChatRequest(BaseModel):
    question: constr(min_length=3) = Field(..., description="User question")
    user_id: str = Field(..., min_length=3)
    trace_id: str | None = None

class ChatResponse(BaseModel):
    answer: str
    sources: list[str]
    latency_ms: int

async def _with_timeout(coro, *, timeout: float):
    return await asyncio.wait_for(coro, timeout=timeout)

@router.post("/chat", response_model=ChatResponse, status_code=status.HTTP_200_OK)
async def chat(
    payload: ChatRequest,
    svc: ChatService = Depends(get_chat_service),
) -> ChatResponse:
    """Answer a user question with retrieval + LLM while enforcing timeouts and structured logs."""
    ctx = {"trace_id": payload.trace_id or str(uuid4()), "user_id": payload.user_id}
    logger.info("chat.request", extra=ctx | {"question": payload.question})
    try:
        result = await _with_timeout(
            svc.answer(question=payload.question, user_id=payload.user_id),
            timeout=8.0,
        )
    except asyncio.TimeoutError:
        logger.warning("chat.timeout", extra=ctx)
        raise HTTPException(status_code=504, detail="Upstream LLM timeout")
    except RetrievalError as exc:
        logger.exception("chat.retrieval_failed", extra=ctx | {"error": str(exc)})
        raise HTTPException(status_code=500, detail="Context retrieval failed")

    logger.info(
        "chat.success",
        extra=ctx | {"sources": result.sources, "latency_ms": result.latency_ms},
    )
    return ChatResponse(
        answer=result.answer,
        sources=result.sources,
        latency_ms=result.latency_ms,
    )
</code>
                    </div>
                    <div class="code-block" data-lang="python" data-title="SQLAlchemy model for chunked documents">
<code>
from __future__ import annotations

from typing import Any
from uuid import uuid4

from sqlalchemy import JSON, Column, DateTime, Float, ForeignKey, Index, String, Text, func
from sqlalchemy.dialects.postgresql import ARRAY, UUID
from sqlalchemy.orm import declarative_base, relationship

Base = declarative_base()

class Document(Base):
    __tablename__ = "documents"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)
    tenant_id = Column(String(36), nullable=False)
    title = Column(String(255), nullable=False)
    source = Column(String(120), nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    chunks = relationship("DocumentChunk", back_populates="document", lazy="selectin")

class DocumentChunk(Base):
    __tablename__ = "document_chunks"
    __table_args__ = (
        Index("ix_chunks_tenant_doc", "tenant_id", "document_id"),
        Index("ix_chunks_vector", "tenant_id", "embedding", postgresql_using="ivfflat"),
    )

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)
    tenant_id = Column(String(36), nullable=False)
    document_id = Column(UUID(as_uuid=True), ForeignKey("documents.id"), nullable=False)
    content = Column(Text, nullable=False)
    embedding = Column(ARRAY(Float), nullable=False)
    position = Column(Float, nullable=False, default=0)
    metadata = Column(JSON, default=dict)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    document = relationship("Document", back_populates="chunks", lazy="joined")

    def as_context(self, score: float) -> dict[str, Any]:
        return {
            "id": str(self.id),
            "score": round(score, 4),
            "content": self.content,
            "source": self.metadata.get("source", self.document.source),
        }
</code>
                    </div>
                </div>
                <div class="diagram">
<div class="mermaid">
graph LR
    User((User)) -->|question| API[FastAPI service]
    API --> Retriever[Retrieval layer]
    Retriever --> VectorDB[(Vector DB)]
    Retriever --> PG[(PostgreSQL)]
    Retriever --> LLM[LLM Provider]
    LLM --> API
    API -->|answer + sources| User
</div>
                </div>
                <details class="project-details">
                    <summary>View more details</summary>
                    <p>Hard limits on upstream LLM calls with graceful degradation, structured logs shipped to OpenTelemetry collector, and daily refresh of embeddings via Celery worker. CI deploys Docker image to Azure App Service with health checks and smoke tests against staging database snapshots.</p>
                </details>
            </article>
            <article class="project-card" id="project-rag-support">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">RAG System for Customer Support</h3>
                        <p class="sub">RAG pipeline that helps support teams answer tickets using a knowledge base and historical conversations.</p>
                    </div>
                    <div class="stack">Python  |  LangChain  |  Chroma  |  Azure OpenAI  |  Redis  |  pytest</div>
                </div>
                <ul class="project-points">
                    <li>Designed ingest -> chunk -> embed -> store -> retrieve -> answer flow with adapters per source.</li>
                    <li>Normalized FAQ, markdown docs and call transcripts before chunking.</li>
                    <li>Added evaluation harness and prompt A/B tests with simple heuristics.</li>
                    <li>Unit and integration tests with pytest plus ephemeral Chroma instances.</li>
                </ul>
                <div class="code-grid">
                    <div class="code-block" data-lang="python" data-title="RAG pipeline builder with metrics logging">
<code>
from __future__ import annotations

import logging
from collections import Counter
from dataclasses import dataclass
from typing import Iterable, Sequence

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import AzureOpenAIEmbeddings

logger = logging.getLogger("rag.pipeline")

@dataclass
class RawDocument:
    content: str
    source: str
    topic: str

@dataclass
class PipelineStats:
    chunks: int = 0
    tokens_est: int = 0
    sources: Counter[str] = Counter()

    def log(self) -> None:
        logger.info(
            "rag.ingest_completed",
            extra={
                "chunks": self.chunks,
                "tokens_est": self.tokens_est,
                "top_sources": self.sources.most_common(3),
            },
        )

def build_rag_index(
    docs: Sequence[RawDocument],
    collection: Chroma,
    embedder: AzureOpenAIEmbeddings,
) -> PipelineStats:
    """Normalize, chunk, embed and persist documents with basic ingest metrics."""
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=80)
    stats = PipelineStats()

    for doc in docs:
        normalized = doc.content.strip().replace("\r\n", "\n")
        for chunk in splitter.split_text(normalized):
            emb = embedder.embed_query(chunk)
            collection.add_texts(
                texts=[chunk],
                embeddings=[emb],
                metadatas=[{"source": doc.source, "topic": doc.topic}],
            )
            stats.chunks += 1
            stats.tokens_est += max(len(chunk) // 4, 1)
            stats.sources[doc.source] += 1

    stats.log()
    return stats
</code>
                    </div>
                    <div class="code-block" data-lang="python" data-title="Pytest for retrieval &amp; answer quality">
<code>
import pytest
from langchain.vectorstores import Chroma

from rag.answer import answer_question
from rag.pipeline import RawDocument, build_rag_index

@pytest.fixture(scope="module")
def small_kb(tmp_path_factory):
    path = tmp_path_factory.mktemp("kb")
    store = Chroma(collection_name="support", persist_directory=str(path))
    docs = [
        RawDocument("Reset password via Settings -> Security", source="faq", topic="auth"),
        RawDocument("Refunds are processed within 7 days", source="policy", topic="billing"),
    ]
    build_rag_index(docs, collection=store, embedder=fake_embeddings())
    yield store
    store.delete_collection()

def fake_embeddings():
    class _Fake:
        def embed_query(self, text: str):
            return [hash(text) % 1000 / 1000 for _ in range(1536)]
    return _Fake()

def test_retrieval_and_answer_quality(small_kb):
    question = "How long do refunds take?"
    answer, meta = answer_question(question, store=small_kb)

    assert meta.similarity >= 0.68
    assert "7 days" in answer.lower()
    assert meta.source in {"faq", "policy"}
</code>
                    </div>
                </div>
                <div class="diagram">
<div class="mermaid">
flowchart LR
    Ingest[Ingest adapters] --> Normalize[Normalize per source]
    Normalize --> Chunk[Smart chunking]
    Chunk --> Embed[Embeddings]
    Embed --> Chroma[(Chroma DB)]
    UserQ[User ticket] --> Retrieve[Retriever]
    Retrieve --> Chroma
    Retrieve --> Compose[LLM composer]
    Compose --> Answer[Answer + citations]
</div>
<table class="metrics-table">
    <thead><tr><th>Prompt variant</th><th>Precision</th><th>Recall</th><th>Avg. latency (ms)</th></tr></thead>
    <tbody>
        <tr><td>v1-short</td><td>0.74</td><td>0.69</td><td>820</td></tr>
        <tr><td>v2-grounded</td><td>0.81</td><td>0.76</td><td>910</td></tr>
        <tr><td>v3-safety</td><td>0.78</td><td>0.80</td><td>1010</td></tr>
    </tbody>
</table>
                </div>
                <details class="project-details">
                    <summary>View more details</summary>
                    <p>Cached embeddings in Redis, used semantic filters by topic and source, and added nightly evaluation jobs to compare prompt variants. Alerts fire when similarity drops or latency spikes, using simple thresholds in Prometheus-compatible metrics.</p>
                </details>
            </article>
            <article class="project-card" id="project-agentic-cleaning">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Agentic Workflow for Data Cleaning</h3>
                        <p class="sub">AI agent that cleans and normalises tabular data before analytics, escalating ambiguous fixes.</p>
                    </div>
                    <div class="stack">Python  |  Pandas  |  NumPy  |  LangGraph/CrewAI  |  Azure Functions  |  PostgreSQL</div>
                </div>
                <ul class="project-points">
                    <li>Detected missing data, anomalies and inconsistencies across ingestion batches.</li>
                    <li>Agent proposed fixes and mappings; escalated uncertain cases for review.</li>
                    <li>Audit logs stored in PostgreSQL with before/after values per change.</li>
                    <li>Documented architecture and sequence for handoffs.</li>
                </ul>
                <div class="code-grid">
                    <div class="code-block" data-lang="python" data-title="Detect anomalies with Pandas/NumPy">
<code>
from __future__ import annotations

from dataclasses import dataclass
from typing import Any

import numpy as np
import pandas as pd

@dataclass
class Issue:
    row_id: Any
    column: str
    issue: str
    suggested_fix: str

def detect_anomalies(frame: pd.DataFrame, z_threshold: float = 3.2) -> list[Issue]:
    """Detect outliers, missing values and ambiguous textual delimiters."""
    issues: list[Issue] = []
    numeric_cols = frame.select_dtypes(include=["number"]).columns

    for col in numeric_cols:
        series = frame[col]
        z_scores = np.abs((series - series.mean()) / (series.std() or 1))
        for idx in series.index[z_scores > z_threshold]:
            issues.append(
                Issue(
                    row_id=idx,
                    column=col,
                    issue="outlier",
                    suggested_fix=f"clip to p99 ({series.quantile(0.99):.2f})",
                )
            )

    for col in frame.columns:
        missing = frame[col].isna()
        if missing.any():
            issues.append(
                Issue(
                    row_id="*",
                    column=col,
                    issue="missing_values",
                    suggested_fix="impute with median or forward fill",
                )
            )
        if frame[col].dtype == "object":
            duplicated = frame[col].str.contains(";|,")
            for idx in frame[duplicated].index:
                issues.append(
                    Issue(
                        row_id=idx,
                        column=col,
                        issue="ambiguous_delimiter",
                        suggested_fix="split field and normalise",
                    )
                )
    return issues
</code>
                    </div>
                    <div class="code-block" data-lang="python" data-title="LangGraph-style agent with audit logging">
<code>
from __future__ import annotations

from langgraph.graph import END, StateGraph

class AuditLogRepository:
    async def write(self, *, row_id: str, column: str, action: str, detail: dict) -> None:
        ...

class State(dict):
    issues: list
    accepted: list
    pending_review: list

def build_data_cleaning_graph(audit_repo: AuditLogRepository):
    """Orchestrate auto-fixes vs escalations and write audit entries for every step."""
    graph = StateGraph(State)

    async def classify(state: State):
        state.setdefault("accepted", [])
        state.setdefault("pending_review", [])
        for issue in state["issues"]:
            if issue.issue == "outlier" and "clip" in issue.suggested_fix:
                state["accepted"].append(issue)
            else:
                state["pending_review"].append(issue)
        return state

    async def apply_fixes(state: State):
        for issue in state["accepted"]:
            await audit_repo.write(
                row_id=str(issue.row_id),
                column=issue.column,
                action="auto_fix",
                detail={"fix": issue.suggested_fix},
            )
        return state

    async def escalate(state: State):
        for issue in state["pending_review"]:
            await audit_repo.write(
                row_id=str(issue.row_id),
                column=issue.column,
                action="needs_confirmation",
                detail={"reason": issue.issue},
            )
        return state

    graph.add_node("classify", classify)
    graph.add_node("apply_fixes", apply_fixes)
    graph.add_node("escalate", escalate)

    graph.set_entry_point("classify")
    graph.add_edge("classify", "apply_fixes")
    graph.add_edge("classify", "escalate")
    graph.add_edge("apply_fixes", END)
    graph.add_edge("escalate", END)

    return graph.compile()
</code>
                    </div>
                </div>
                <div class="diagram">
<div class="mermaid">
sequenceDiagram
    participant Ingest
    participant Agent
    participant Reviewer
    participant Audit
    Ingest->>Agent: anomalies list
    Agent->>Agent: auto-fix eligible?
    Agent-->>Audit: write auto_fix
    Agent-->>Reviewer: request confirmation
    Reviewer-->>Audit: approve/override
</div>
<table class="metrics-table">
    <thead><tr><th>Field</th><th>Before</th><th>Suggested</th><th>After</th></tr></thead>
    <tbody>
        <tr><td>Price</td><td>1,000,000</td><td>Clip to 820,000</td><td>820,000</td></tr>
        <tr><td>Country</td><td>PL; DE</td><td>Split + pick mode</td><td>PL</td></tr>
        <tr><td>Signup date</td><td>-</td><td>Forward fill</td><td>2024-10-02</td></tr>
    </tbody>
</table>
                </div>
                <details class="project-details">
                    <summary>View more details</summary>
                    <p>Azure Function triggers the pipeline per batch, writes anomalies to PostgreSQL and publishes review tasks to Teams via webhook. Maintainers can replay decisions; every change is audit-tracked with before/after snapshots for compliance.</p>
                </details>
            </article>
            <article class="project-card" id="project-eval-dashboard">
                <div class="project-header">
                    <div>
                        <h3 class="project-title">Evaluation Dashboard for LLM Apps</h3>
                        <p class="sub">Internal tool to evaluate and monitor prompts and model configurations over time.</p>
                    </div>
                    <div class="stack">Python  |  FastAPI  |  PostgreSQL  |  SQLAlchemy  |  Plotly  |  GitHub Actions</div>
                </div>
                <ul class="project-points">
                    <li>Backend stores requests, responses, metadata and user ratings.</li>
                    <li>API endpoints expose grouped stats for dashboards and reports.</li>
                    <li>Scheduled batch tests run via GitHub Actions and push results.</li>
                    <li>Charts show success rate and latency trends per model/prompt.</li>
                </ul>
                <div class="code-grid">
                    <div class="code-block" data-lang="python" data-title="FastAPI route for aggregated metrics">
<code>
from __future__ import annotations

from datetime import datetime
from typing import Annotated

from fastapi import APIRouter, Depends, Query
from sqlalchemy import func, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.db import get_session
from app.models import RequestLog

router = APIRouter()

@router.get("/metrics/requests")
async def request_metrics(
    model: Annotated[str | None, Query()] = None,
    prompt_version: Annotated[str | None, Query(alias="prompt")] = None,
    start: Annotated[datetime | None, Query()] = None,
    end: Annotated[datetime | None, Query()] = None,
    session: AsyncSession = Depends(get_session),
):
    """Return aggregated success rates and latency percentiles per model/prompt."""
    stmt = (
        select(
            RequestLog.model,
            RequestLog.prompt_version,
            func.count().label("total"),
            func.sum(func.case((RequestLog.success.is_(True), 1), else_=0)).label("success"),
            func.percentile_cont(0.5).within_group(RequestLog.latency_ms).label("p50"),
            func.percentile_cont(0.95).within_group(RequestLog.latency_ms).label("p95"),
        )
        .where(RequestLog.created_at >= (start or func.now() - func.cast("7 days", func.interval)))
        .group_by(RequestLog.model, RequestLog.prompt_version)
    )

    if model:
        stmt = stmt.where(RequestLog.model == model)
    if prompt_version:
        stmt = stmt.where(RequestLog.prompt_version == prompt_version)
    if end:
        stmt = stmt.where(RequestLog.created_at <= end)

    rows = (await session.execute(stmt)).all()
    return [
        {
            "model": r.model,
            "prompt_version": r.prompt_version,
            "success_rate": round(r.success / r.total, 3),
            "p50_ms": int(r.p50 or 0),
            "p95_ms": int(r.p95 or 0),
        }
        for r in rows
    ]
</code>
                    </div>
                    <div class="code-block" data-lang="yaml" data-title="GitHub Actions: scheduled evaluation run">
<code>
name: nightly-evals

on:
  schedule:
    - cron: "0 2 * * *"
  workflow_dispatch:

jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install
        run: pip install -r requirements.txt
      - name: Run evaluations
        env:
          EVAL_API_BASE: ${{ secrets.EVAL_API_BASE }}
          EVAL_API_TOKEN: ${{ secrets.EVAL_API_TOKEN }}
        run: |
          python scripts/run_evals.py --prompt latest --limit 50 --output metrics.json
      - name: Upload results
        run: |
          curl -H "Authorization: Bearer $EVAL_API_TOKEN" \
               -H "Content-Type: application/json" \
               -d @metrics.json "$EVAL_API_BASE/metrics/import"
</code>
                    </div>
                </div>
                <div class="diagram">
                    <div id="eval-chart" class="chart"></div>
                    <script>
                        document.addEventListener("DOMContentLoaded", function () {
                            const dates = ["2025-01-10", "2025-01-17", "2025-01-24", "2025-01-31"];
                            const success = [0.91, 0.94, 0.9, 0.96];
                            const latency = [820, 790, 860, 740];
                            Plotly.newPlot(
                                "eval-chart",
                                [
                                    { x: dates, y: success, mode: "lines+markers", name: "Success rate", yaxis: "y1" },
                                    { x: dates, y: latency, mode: "lines+markers", name: "P95 latency (ms)", yaxis: "y2" },
                                ],
                                {
                                    margin: { t: 10, r: 30, b: 30, l: 40 },
                                    yaxis: { title: "Success", range: [0.75, 1] },
                                    yaxis2: {
                                        title: "Latency (ms)",
                                        overlaying: "y",
                                        side: "right",
                                        range: [600, 950],
                                    },
                                    legend: { orientation: "h" },
                                    paper_bgcolor: "transparent",
                                    plot_bgcolor: "transparent",
                                },
                                { displayModeBar: false }
                            );
                        });
                    </script>
                </div>
                <details class="project-details">
                    <summary>View more details</summary>
                    <p>Data stored in PostgreSQL with partitions per month. Aggregations use materialized views refreshed via cron. Frontend widgets load via light JS, keeping GitHub Pages friendly while pulling live data from the API.</p>
                </details>
            </article>
        </section>

        <section id="timeline" class="section timeline">
            <div class="section-heading">
                <p class="eyebrow">Timeline</p>
                <h2>Career highlights</h2>
            </div>
            <div class="timeline-grid">
                <div class="timeline-item">
                    <div class="time">Early years</div>
                    <p>Primary &amp; secondary school: built games, websites and scripts; learned to debug and ship things classmates actually used.</p>
                </div>
                <div class="timeline-item">
                    <div class="time">University / self study</div>
                    <p>Deepened algorithms, C++ and Python; kept shipping side projects and tools for friends and NGOs.</p>
                </div>
                <div class="timeline-item">
                    <div class="time">2022 - now</div>
                    <p>Freelance Software Engineer &amp; Automation Developer: backend services, internal tools, integrations.</p>
                </div>
                <div class="timeline-item">
                    <div class="time">2023 - now</div>
                    <p>AI Python Engineer: LLM applications, RAG systems, agents, evaluations and production integrations.</p>
                </div>
            </div>
        </section>

        <section id="contact" class="section contact">
            <div class="section-heading">
                <p class="eyebrow">Contact</p>
                <h2>Let's talk</h2>
            </div>
            <div class="contact-content">
                <a href="mailto:natjiks@gmail.com" class="btn btn-primary contact-email">natjiks@gmail.com</a>
                <div class="contact-links">
                    <a class="btn btn-outline" href="https://github.com/natiixnt" target="_blank" rel="noopener noreferrer">GitHub</a>
                    <a class="btn btn-outline" href="https://www.linkedin.com/in/naithai/" target="_blank" rel="noopener noreferrer">LinkedIn</a>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">Built with lightweight HTML/CSS/JS and hosted on GitHub Pages.</footer>

    <script src="js/scripts.js"></script>
</body>
</html>

